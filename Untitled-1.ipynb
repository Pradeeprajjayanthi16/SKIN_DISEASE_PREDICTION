{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (1.1.21)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (1.22.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (0.18.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (1.26.12)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->roboflow) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->roboflow) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->roboflow) (2.1.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (from supervision->roboflow) (0.7.1)\n",
      "Requirement already satisfied: scipy==1.10.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from supervision->roboflow) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Skin-disease-prediction-4 to coco:: 100%|██████████| 96221/96221 [00:18<00:00, 5254.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Skin-disease-prediction-4 in coco:: 100%|██████████| 5726/5726 [00:02<00:00, 2301.08it/s]\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"IfjlGXuiNMDTNkysEDeV\")\n",
    "project = rf.workspace(\"work-3dka0\").project(\"skin-disease-prediction-1ej1a\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"coco\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.2.1+cu121)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\classic\\appdata\\roaming\\python\\python38\\site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available for training.\n",
      "NVIDIA GeForce GTX 1650 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available for training.\")\n",
    "else:\n",
    "    print(\"GPU is not available, training will be done on CPU.\")\n",
    "\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1650 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.2.1+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\classic\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: thop, torchaudio, torchvision, ultralytics\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        img = coco.loadImgs(img_id)[0]\n",
    "        path = img['file_name']\n",
    "        \n",
    "        image = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox']\n",
    "            # Convert bbox from [x, y, width, height] to [x_min, y_min, x_max, y_max]\n",
    "            x_min, y_min, width, height = bbox\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "            if width > 0 and height > 0:\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(ann['category_id'])\n",
    "                masks.append(coco.annToMask(ann))\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            return self.__getitem__((index + 1) % len(self.ids))\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = np.stack(masks)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['masks'] = masks\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# Define transformations\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "# Load dataset\n",
    "dataset = SkinDiseaseDataset(root='Skin-disease-prediction-4/train', annFile='Skin-disease-prediction-4/train/_annotations.coco.json', transforms=get_transform(train=True))\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Load pre-trained Mask R-CNN model\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
    "weights = MaskRCNN_ResNet50_FPN_Weights.COCO_V1\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=weights)\n",
    "\n",
    "# Replace the classifier with a new one, that has num_classes which is user-defined\n",
    "num_classes = 21  # 20 classes + 1 background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Replace the mask predictor with a new one\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {losses.item()}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mask_rcnn_skin_disease.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\CLASSIC/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:20<00:00, 4.93MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        img = coco.loadImgs(img_id)[0]\n",
    "        path = img['file_name']\n",
    "        \n",
    "        image = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox']\n",
    "            # Convert bbox from [x, y, width, height] to [x_min, y_min, x_max, y_max]\n",
    "            x_min, y_min, width, height = bbox\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "            if width > 0 and height > 0:\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(ann['category_id'])\n",
    "                masks.append(coco.annToMask(ann))\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            return self.__getitem__((index + 1) % len(self.ids))\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = np.stack(masks)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['masks'] = masks\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# Define transformations\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = SkinDiseaseDataset(root='Skin-disease-prediction-4/valid', annFile='Skin-disease-prediction-4/valid/_annotations.coco.json', transforms=get_transform(train=False))\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None)\n",
    "num_classes = 21  # 20 classes + 1 background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "model.load_state_dict(torch.load('mask_rcnn_skin_disease.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        outputs = model(images, targets)\n",
    "        # Process outputs to calculate metrics (e.g., accuracy, IoU, etc.)\n",
    "        # Example: print the outputs\n",
    "        print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
